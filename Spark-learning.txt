the table is generally divided into two types:
1)fact table :  The fact table generally records water, such as sales lists, etc., usually with the growth of time constantly expanding.... means large tables
2)dimension table: Dimension tables (small tables) generally refer to fixed, less variable tables, such as contacts, items, etc., the general data is limited.


=============================================
JOINS :
------
1) We did not specify that we wanted to do an “inner-join”, by default spark performs an inner-join if no join type is given.
2)Either you should skip the join type or the column name should be wrapped into scala Seq if have a join type.



===============================================
Broadcast hash join :
--------------------
1) Table needs to be broadcast less than  spark.sql.autoBroadcastJoinThreshold the configured value,
   default 10M (or add a broadcast join the hint)
2) Base table can not be broadcast, such as the left outer join, only broadcast the right table.

3) In broadcast hash join, copy of one of the join relations are being sent to all the worker nodes and it saves shuffling cost. This is useful when you are joining a large relation with a smaller one. It is also known as map-side join(associating worker nodes with mappers).

// Create the Execution Plan
fact_table = fact_table.join(broadcast(dimension_table), // Here's the magic!
                         fact_table.col("dimension_id") === dimension_table.col("id"))

================================================
Sort Merge Joins :
------------------

================================================
Triggers :
----------

trigger create mirco-batch with specified time interval.
===============================================
Adaptive Query executions :
---------------------------
1) selecting joins strategy runtime - either broadcast join or sort merge join
2) selecting no.of partitions - default 200
3) data skew problem

for this we need to globally enable - spar.sql.adaptive.enabled=true
================================================

Speculative execution in spark:
-------------------------------
to handle slow running tasks in spark.
to enable spark.speculation= true

